ðŸ“¹ Real-Time Video Capture & Inference Overlay

This project demonstrates a browser-based real-time video streaming and inference overlay system.
It supports two modes:

Server Mode â€“ phone streams frames to a Node.js backend for inference.

WASM Mode â€“ inference runs directly in the browser (WebAssembly).

The viewer overlays bounding boxes (detections) on live video, synchronized by frame_id and timestamps (capture_ts, recv_ts, inference_ts).

ðŸš€ Quick Start
1. Clone Repo
git clone https://github.com/yourname/realtime-overlay.git
cd realtime-overlay

2. One-Command Start (with Docker)
./start.sh server


or

./start.sh wasm


This will:

Build & start containers (docker-compose up)

Launch server (if in server mode)

Serve frontend (viewer.html, phone.html)

ðŸ“± Joining from Phone

Ensure your phone and laptop are on the same WiFi/network.

Open the viewer.html on your laptop (e.g., http://localhost:8080/viewer.html).

On the laptop viewer, a QR code / short URL will be displayed.

Scan the QR with your phone â†’ it opens phone.html.

Phone camera starts automatically.

Frames + metadata stream to the server (or directly if in WASM mode).

ðŸ”§ Modes
Server Mode

Run ./start.sh server

Phone â†’ sends video frames to Node.js server

Server â†’ attaches inference_ts after running detection

Viewer â†’ overlays results

WASM Mode

Run ./start.sh wasm

No server needed

Phone/browser runs inference locally (WebAssembly model)

Works fully offline

ðŸ“‚ Repo Structure
.
â”œâ”€â”€ server.js           # Node.js WebSocket relay (server mode)
â”œâ”€â”€ viewer.html         # Viewer (video + overlay)
â”œâ”€â”€ phone.html          # Phone capture client
â”œâ”€â”€ Dockerfile          # For frontend/server build
â”œâ”€â”€ docker-compose.yml  # Compose setup
â”œâ”€â”€ start.sh            # Convenience start script
â”œâ”€â”€ README.md           # You are here
â””â”€â”€ report.md           # Design notes, low-resource mode, backpressure

ðŸ“Š Example Metadata

Each frame sends JSON like:

{
  "frame_id": "123",
  "capture_ts": 1690000000000,
  "recv_ts": 1690000000100,
  "inference_ts": 1690000000120,
  "detections": [
    { "label": "person", "score": 0.93, "xmin": 0.12, "ymin": 0.08, "xmax": 0.34, "ymax": 0.67 }
  ]
}


Coordinates are normalized [0..1]

Browser uses frame_id + capture_ts to align overlays

End-to-end latency = inference_ts - capture_ts

âš¡ Backpressure Handling

Frame skipping when network is slow

Adaptive FPS (e.g., 30 â†’ 10fps)

Minimal JSON metadata per frame

âœ… Requirements

Docker & docker-compose

Modern browser (Chrome/Edge/Firefox/Safari â‰¥ 16)

iOS Safari users must enable camera permissions